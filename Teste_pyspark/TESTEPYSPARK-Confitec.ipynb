{"cells":[{"cell_type":"code","source":["## IMPORTANDO BIBLIOTECAS ###########################################################################################################\n\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.types import *\nfrom pyspark.sql import functions as F\nimport re\nfrom datetime import datetime ,timedelta"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"4c81fa29-af42-4b51-88dc-bc541578cb32","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["## CONFIGURAÇÕES AMBIENTE ############################################################################################################\n\nspark.conf.set(\"spark.sql.legacy.timeParserPolicy\", \"Legacy\") # para schemas de parquet diferente"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"e7ca4236-dff4-43a2-b8d5-b1ba65341fab","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["## VARIÁVEIS DE EXECUÇÃO DO PROCESSO ################################################################################################\n\ndict_PARAMETRO = {\n      'Caminho_parquet'  : '/FileStore/tables/dados/OriginaisNetflix.parquet'\n     ,'Caminho' : '/FileStore/tables/dados/CSV/'\n                 }\n\nvCAMINHO = dict_PARAMETRO['Caminho']\nvCAMINHOARQUIVO = dict_PARAMETRO['Caminho_parquet']\n\n\n## VARIAVEIS DE REGRA ##############################################################################################################\n\ndict_MES =  {\"jan\" : \"01\"\n            ,\"feb\" : \"02\"\n            ,\"mar\" : \"03\"\n            ,\"apr\" : \"04\"\n            ,\"may\" : \"05\"\n            ,\"jun\" : \"06\"\n            ,\"jul\" : \"07\"\n            ,\"aug\" : \"08\"\n            ,\"sep\" : \"09\"\n            ,\"oct\" : \"10\"\n            ,\"nov\" : \"11\"\n            ,\"dec\" : \"12\"}"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"0e5d8252-3da1-4990-be75-fd7298181b27","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["## INICIO TRATATIVA DE DADOS ######################################################################################################\n\ndf_TEMP = spark.read.parquet(vCAMINHOARQUIVO,inferSchema=True)\n\n## ALTERANDO CAMPOS \"Premiere\" e \"dt_inclusao\" DE STRING PARA DATETIME ############################################################\n\nfor vMES in list(dict_MES):\n    df_TEMP = df_TEMP.withColumn('Premiere',F.regexp_replace(F.lower(df_TEMP['Premiere']), vMES, dict_MES[vMES]))\n    \ndf_TEMP = (df_TEMP.withColumn('Premiere',F.to_timestamp(F.to_date(df_TEMP['Premiere'],'dd-MM-yy'),'yyyy-MM-dd hh:mm:ss'))\n                  .withColumn('dt_inclusao',F.to_utc_timestamp(df_TEMP['dt_inclusao'],'UTC+03:00')))\n\n## CLASSIFICANDO PELA COLUNA \"ACTIVE\" E PELA COLUNA \"GENRE\" ########################################################################\n\ndf_TEMP = df_TEMP.sort(df_TEMP.Active.desc(),df_TEMP.Genre.desc())\n\n## REMOVENDO DUPLICATAS ############################################################################################################\n\ndf_TEMP = df_TEMP.dropDuplicates()\n\n## TROCANDO RESULTADOS DA COLUNA \"SEASONS\" DE \"TBA\" PARA \"A SER ANUNCIADO\" ########################################################\n\ndf_TEMP = df_TEMP.withColumn('Seasons',F.regexp_replace(df_TEMP['Seasons'], 'TBA', 'a ser anunciado'))\n\n## CRIANDO COLUNA DATA DE ALTERAÇÃO ###############################################################################################\n\ndf_TEMP = df_TEMP.withColumn('Data de Alteração',F.lit(datetime.now()))\n\n## RENOMEANDO COLUNAS PARA PORTUGUES ##############################################################################################\n\ndf_FINAL = (df_TEMP.withColumnRenamed(\"Title\",\"Título\")\n                 .withColumnRenamed(\"Genre\",\"Gênero\")\n                 .withColumnRenamed(\"GenreLabels\",\"Etiqueta de Gênero\")\n                 .withColumnRenamed(\"Premiere\",\"Estréia\")\n                 .withColumnRenamed(\"Seasons\",\"Temporadas\")\n                 .withColumnRenamed(\"SeasonsParsed\",\"Temporadas Analisadas\")\n                 .withColumnRenamed(\"EpisodesParsed\",\"Episódios Analisadas\")\n                 .withColumnRenamed(\"Length\",\"Duração\")\n                 .withColumnRenamed(\"MinLength\",\"Duração Mínima\")\n                 .withColumnRenamed(\"MaxLength\",\"Duração Máxima\")\n                 .withColumnRenamed(\"Status\",\"Situação\")\n                 .withColumnRenamed(\"Active\",\"Ativo\")\n                 .withColumnRenamed(\"Table\",\"Categoria\")\n                 .withColumnRenamed(\"Language\",\"Idioma\")\n                 .withColumnRenamed(\"dt_inclusao\",\"Data Inclusão\")\n          )"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"73991b5d-e144-42e7-b5cd-aba9362b1920","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["## CRIANDO ARQUIVO CSV E SALVANDO DENTRO DO BUCKET ##############################################################################\n\ndf_FINAL.write.format(\"com.databricks.spark.csv\").mode(\"overwrite\").option(\"header\", \"true\").save(vCAMINHO+'OriginaisNetflix.csv')"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"344ac4e8-ca16-4a25-b723-ccbc77163ed7","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"TESTEPYSPARK-Confitec","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":954840930235582}},"nbformat":4,"nbformat_minor":0}
